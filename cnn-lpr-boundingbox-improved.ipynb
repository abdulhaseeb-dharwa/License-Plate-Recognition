{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import kagglehub\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Download dataset\n",
    "print(\"Downloading dataset...\")\n",
    "dataset_path = kagglehub.dataset_download('fareselmenshawii/large-license-plate-dataset')\n",
    "img_train_dir = os.path.join(dataset_path, 'images', 'train')\n",
    "img_val_dir = os.path.join(dataset_path, 'images', 'val')\n",
    "label_train_dir = os.path.join(dataset_path, 'labels', 'train')\n",
    "label_val_dir = os.path.join(dataset_path, 'labels', 'val')\n",
    "print(\"Dataset downloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Architecture\n",
    "class LicensePlateCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LicensePlateCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv_residual = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 4)\n",
    "        print(\"Model initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        identity = x\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        identity = self.conv_residual(identity)\n",
    "        x = x + identity\n",
    "        x = torch.relu(x)\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.relu(self.bn5(self.conv5(x)))\n",
    "        x = torch.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc(x))  # Ensure bbox coords in 0-1 range\n",
    "        return x\n",
    "\n",
    "# Custom Dataset\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_files = sorted(glob(os.path.join(img_dir, '*.jpg')))\n",
    "        self.label_files = sorted(glob(os.path.join(label_dir, '*.txt')))\n",
    "        print(f\"Loaded {len(self.img_files)} images and {len(self.label_files)} labels\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_files[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label_path = self.label_files[idx]\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        if lines:\n",
    "            _, x_center, y_center, width, height = map(float, lines[0].strip().split())\n",
    "            x_min = (x_center - width / 2)\n",
    "            y_min = (y_center - height / 2)\n",
    "            x_max = (x_center + width / 2)\n",
    "            y_max = (y_center + height / 2)\n",
    "            bbox = np.array([x_min, y_min, x_max, y_max], dtype=np.float32)\n",
    "        else:\n",
    "            bbox = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "        image = self.transform(image)\n",
    "        return image, torch.tensor(bbox)\n",
    "\n",
    "# IoU Calculation\n",
    "\n",
    "def calculate_iou(pred, target):\n",
    "    x1_p, y1_p, x2_p, y2_p = pred\n",
    "    x1_t, y1_t, x2_t, y2_t = target\n",
    "\n",
    "    x1_i = max(x1_p, x1_t)\n",
    "    y1_i = max(y1_p, y1_t)\n",
    "    x2_i = min(x2_p, x2_t)\n",
    "    y2_i = min(y2_p, y2_t)\n",
    "\n",
    "    inter_area = max(0, x2_i - x1_i) * max(0, y2_i - y1_i)\n",
    "    pred_area = max(0, x2_p - x1_p) * max(0, y2_p - y1_p)\n",
    "    true_area = max(0, x2_t - x1_t) * max(0, y2_t - y1_t)\n",
    "\n",
    "    union_area = pred_area + true_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Training and Evaluation\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs} started\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_iou = 0\n",
    "        for images, bboxes in tqdm(train_loader, desc=\"Training\"):\n",
    "            images, bboxes = images.to(device), bboxes.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, bboxes)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            for pred, true in zip(outputs.detach().cpu().numpy(), bboxes.cpu().numpy()):\n",
    "                train_iou += calculate_iou(pred, true)\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_iou /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_iou = 0\n",
    "        with torch.no_grad():\n",
    "            for images, bboxes in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images, bboxes = images.to(device), bboxes.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, bboxes).item()\n",
    "                for pred, true in zip(outputs.detach().cpu().numpy(), bboxes.cpu().numpy()):\n",
    "                    val_iou += calculate_iou(pred, true)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "\n",
    "# Inference\n",
    "\n",
    "def infer(model, image_path, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    print(f\"Running inference on {image_path}\")\n",
    "    model.eval()\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    orig_shape = image.shape[:2]\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "    image_tensor = torch.from_numpy(image_resized.transpose(2, 0, 1)).float() / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bbox = model(image_tensor)[0].cpu().numpy()\n",
    "\n",
    "    bbox[0::2] *= orig_shape[1]\n",
    "    bbox[1::2] *= orig_shape[0]\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset = LicensePlateDataset(img_train_dir, label_train_dir)\n",
    "    val_dataset = LicensePlateDataset(img_val_dir, label_val_dir)\n",
    "\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "    print(\"Initializing model...\")\n",
    "    model = LicensePlateCNN()\n",
    "    print(\"Starting training...\")\n",
    "    train_model(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "    print(\"Performing inference...\")\n",
    "    sample_image = train_dataset.img_files[0]\n",
    "    bbox = infer(model, sample_image)\n",
    "    print(f\"Predicted Bounding Box: {bbox}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
